{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "be725e0de8fb3f5fda9b0118bdf797fa9814e28e467c1cce77c5b9910d8a1786"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Breast Cancer\r\n",
    "- https://www.kaggle.com/shasun/tool-wear-detection-in-cnc-mill\r\n",
    "- Predict \"Machining_Process\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.datasets import load_breast_cancer\r\n",
    "import pandas as pd\r\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Number of features to select.\r\n",
    "max_features = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transform X with variance selector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\r\n",
    "\r\n",
    "dataObj = load_breast_cancer()\r\n",
    "X = dataObj.data\r\n",
    "y = dataObj.target\r\n",
    "colsX = dataObj.feature_names\r\n",
    "\r\n",
    "# Creating object\r\n",
    "sel = VarianceThreshold(threshold=0)\r\n",
    "\r\n",
    "# Fitting\r\n",
    "sel.fit(X)\r\n",
    "\r\n",
    "# Boolean\r\n",
    "sup = sel.get_support()\r\n",
    "cols_sel = colsX[sup]\r\n",
    "print(f'Chosen columns:')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_sel, sep=', ')\r\n",
    "\r\n",
    "cols_rem = colsX[np.logical_not(sup)]\r\n",
    "print(f'\\nRemoved columns:')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_rem, sep=', ')\r\n",
    "\r\n",
    "X = sel.transform(X)\r\n",
    "dfX = pd.DataFrame(data=X, columns=cols_sel)\r\n",
    "display(dfX.head())\r\n",
    "\r\n",
    "# Initialize dictionary to store selector\r\n",
    "sel = {}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Chosen columns:\n",
      "------------------------------\n",
      "mean radius, mean texture, mean perimeter, mean area, mean smoothness, mean compactness, mean concavity, mean concave points, mean symmetry, mean fractal dimension, radius error, texture error, perimeter error, area error, smoothness error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst radius, worst texture, worst perimeter, worst area, worst smoothness, worst compactness, worst concavity, worst concave points, worst symmetry, worst fractal dimension\n",
      "\n",
      "Removed columns:\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## L1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.feature_selection import SelectFromModel\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "# Split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\r\n",
    "stdsc = StandardScaler()\r\n",
    "X_train_std = stdsc.fit_transform(X_train)\r\n",
    "print(X_train_std.shape)\r\n",
    "# Classifier\r\n",
    "lr = LogisticRegression(solver='liblinear', penalty='l1', C=0.1, multi_class='ovr')\r\n",
    "\r\n",
    "# Create selector object\r\n",
    "threshold=1e-5\r\n",
    "sel['L1'] = SelectFromModel(estimator=lr, norm_order=1, threshold=threshold, max_features=max_features)\r\n",
    "\r\n",
    "# Training\r\n",
    "sel['L1'].fit(X_train_std, y_train)\r\n",
    "\r\n",
    "# Extract norm of weights\r\n",
    "coef = sel['L1'].estimator_.coef_\r\n",
    "coef_norm = np.linalg.norm(coef , ord=1, axis=0)\r\n",
    "\r\n",
    "# Get column boolean\r\n",
    "sup = sel['L1'].get_support()\r\n",
    "print('\\nSupport array')\r\n",
    "print('-'*30)\r\n",
    "print(*sup, sep=', ')\r\n",
    "\r\n",
    "# Store selector\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(398, 30)\n",
      "\n",
      "Support array\n",
      "------------------------------\n",
      "False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, True, False, False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Sort array from based on weights from large to small\r\n",
    "cols = dfX.columns\r\n",
    "idxs = np.argsort(coef_norm)[::-1]\r\n",
    "sup = sup[idxs]\r\n",
    "coef_norm = coef_norm[idxs]\r\n",
    "cols = cols[idxs]\r\n",
    "\r\n",
    "# Print results\r\n",
    "for count, (col, coef) in enumerate(zip(cols, coef_norm)):\r\n",
    "    print(f\"{count+1:2d}) {col:30s} \\t{coef:5.3f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 1) worst radius                   \t2.031\n",
      " 2) mean concave points            \t0.888\n",
      " 3) worst concave points           \t0.710\n",
      " 4) worst texture                  \t0.579\n",
      " 5) mean concavity                 \t0.238\n",
      " 6) worst symmetry                 \t0.121\n",
      " 7) worst smoothness               \t0.052\n",
      " 8) mean compactness               \t0.000\n",
      " 9) mean fractal dimension         \t0.000\n",
      "10) mean symmetry                  \t0.000\n",
      "11) worst fractal dimension        \t0.000\n",
      "12) texture error                  \t0.000\n",
      "13) mean smoothness                \t0.000\n",
      "14) mean area                      \t0.000\n",
      "15) mean perimeter                 \t0.000\n",
      "16) mean texture                   \t0.000\n",
      "17) radius error                   \t0.000\n",
      "18) smoothness error               \t0.000\n",
      "19) perimeter error                \t0.000\n",
      "20) area error                     \t0.000\n",
      "21) compactness error              \t0.000\n",
      "22) concavity error                \t0.000\n",
      "23) concave points error           \t0.000\n",
      "24) symmetry error                 \t0.000\n",
      "25) fractal dimension error        \t0.000\n",
      "26) worst perimeter                \t0.000\n",
      "27) worst area                     \t0.000\n",
      "28) worst compactness              \t0.000\n",
      "29) worst concavity                \t0.000\n",
      "30) mean radius                    \t0.000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Print columns\r\n",
    "cols_sel = cols[sup]\r\n",
    "print('\\nChosen columns')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_sel, sep=', ')\r\n",
    "\r\n",
    "cols_rem = cols[np.logical_not(sup)]\r\n",
    "print(f'\\nRemoved columns')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_rem, sep=', ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Chosen columns\n",
      "------------------------------\n",
      "worst radius, mean concave points, worst concave points, worst texture, mean concavity\n",
      "\n",
      "Removed columns\n",
      "------------------------------\n",
      "worst symmetry, worst smoothness, mean compactness, mean fractal dimension, mean symmetry, worst fractal dimension, texture error, mean smoothness, mean area, mean perimeter, mean texture, radius error, smoothness error, perimeter error, area error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst perimeter, worst area, worst compactness, worst concavity, mean radius\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "# Split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\r\n",
    "stdsc = StandardScaler()\r\n",
    "X_train_std = stdsc.fit_transform(X_train)\r\n",
    "print(X_train_std.shape)\r\n",
    "\r\n",
    "#Create classifier\r\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=0, n_jobs=-1)\r\n",
    "\r\n",
    "#Create object\r\n",
    "threshold = 1e-15\r\n",
    "sel['imp'] = SelectFromModel(forest, threshold=threshold, max_features=max_features)\r\n",
    "\r\n",
    "# Training (Actually, it does not matter whether we have X_train_std or X_train because random forrest does not care)\r\n",
    "sel['imp'].fit(X_train_std, y_train)\r\n",
    "\r\n",
    "# Columns chosen\r\n",
    "sup = sel['imp'].get_support()\r\n",
    "\r\n",
    "# Extract importances values\r\n",
    "importances = sel['imp'].estimator_.feature_importances_\r\n",
    "\r\n",
    "# Select only chosen columns\r\n",
    "print('\\nSupport array')\r\n",
    "print('-'*30)\r\n",
    "print(*sup, sep=', ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(398, 30)\n",
      "\n",
      "Support array\n",
      "------------------------------\n",
      "False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, True, False, False, False, True, False, False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Sort array from based on importances from large to small\r\n",
    "cols = dfX.columns\r\n",
    "idxs = np.argsort(importances)[::-1]\r\n",
    "sup = sup[idxs]\r\n",
    "importances = importances[idxs]\r\n",
    "cols = cols[idxs]\r\n",
    "\r\n",
    "# Print results\r\n",
    "for count, (col, importance) in enumerate(zip(cols, importances)):\r\n",
    "    print(f\"{count+1:2d}) {col:30s} \\t{importance:5.3f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 1) worst perimeter                \t0.151\n",
      " 2) worst radius                   \t0.123\n",
      " 3) worst concave points           \t0.116\n",
      " 4) worst area                     \t0.104\n",
      " 5) mean concave points            \t0.100\n",
      " 6) mean concavity                 \t0.065\n",
      " 7) mean perimeter                 \t0.047\n",
      " 8) worst concavity                \t0.041\n",
      " 9) mean area                      \t0.039\n",
      "10) mean radius                    \t0.038\n",
      "11) area error                     \t0.026\n",
      "12) radius error                   \t0.020\n",
      "13) worst texture                  \t0.016\n",
      "14) perimeter error                \t0.013\n",
      "15) mean texture                   \t0.013\n",
      "16) mean compactness               \t0.012\n",
      "17) worst compactness              \t0.011\n",
      "18) worst smoothness               \t0.010\n",
      "19) worst symmetry                 \t0.008\n",
      "20) worst fractal dimension        \t0.007\n",
      "21) texture error                  \t0.005\n",
      "22) mean smoothness                \t0.005\n",
      "23) compactness error              \t0.004\n",
      "24) concavity error                \t0.004\n",
      "25) symmetry error                 \t0.004\n",
      "26) concave points error           \t0.004\n",
      "27) mean fractal dimension         \t0.003\n",
      "28) mean symmetry                  \t0.003\n",
      "29) fractal dimension error        \t0.003\n",
      "30) smoothness error               \t0.003\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Print columns\r\n",
    "cols_sel = cols[sup]\r\n",
    "print('\\nChosen columns')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_sel, sep=', ')\r\n",
    "\r\n",
    "cols_rem = cols[np.logical_not(sup)]\r\n",
    "print(f'\\nRemoved columns')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_rem, sep=', ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Chosen columns\n",
      "------------------------------\n",
      "worst perimeter, worst radius, worst concave points, worst area, mean concave points\n",
      "\n",
      "Removed columns\n",
      "------------------------------\n",
      "mean concavity, mean perimeter, worst concavity, mean area, mean radius, area error, radius error, worst texture, perimeter error, mean texture, mean compactness, worst compactness, worst smoothness, worst symmetry, worst fractal dimension, texture error, mean smoothness, compactness error, concavity error, symmetry error, concave points error, mean fractal dimension, mean symmetry, fractal dimension error, smoothness error\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sequential feature selector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\r\n",
    "\r\n",
    "# Split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\r\n",
    "stdsc = StandardScaler()\r\n",
    "X_train_std = stdsc.fit_transform(X_train)\r\n",
    "print(X_train_std.shape)\r\n",
    "\r\n",
    "# Create classifier\r\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\r\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\r\n",
    "\r\n",
    "# Create selector object\r\n",
    "sel['seq_forward'] = SequentialFeatureSelector(knn, direction='forward', n_features_to_select=max_features, scoring='accuracy', cv=3, n_jobs=-1)\r\n",
    "\r\n",
    "# Training\r\n",
    "sel['seq_forward'].fit(X_train_std, y_train)\r\n",
    "\r\n",
    "# Get column boolean\r\n",
    "sup = sel['seq_forward'].get_support()\r\n",
    "print('\\nSupport array')\r\n",
    "print('-'*30)\r\n",
    "print(*sup, sep=', ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(398, 30)\n",
      "\n",
      "Support array\n",
      "------------------------------\n",
      "False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, True, False, False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Print columns\r\n",
    "cols = dfX.columns\r\n",
    "cols_sel = cols[sup]\r\n",
    "print('\\nChosen columns')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_sel, sep=', ')\r\n",
    "\r\n",
    "cols_rem = cols[np.logical_not(sup)]\r\n",
    "print(f'\\nRemoved columns')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_rem, sep=', ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Chosen columns\n",
      "------------------------------\n",
      "mean texture, mean area, worst radius, worst texture, worst concave points\n",
      "\n",
      "Removed columns\n",
      "------------------------------\n",
      "mean radius, mean perimeter, mean smoothness, mean compactness, mean concavity, mean concave points, mean symmetry, mean fractal dimension, radius error, texture error, perimeter error, area error, smoothness error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst perimeter, worst area, worst smoothness, worst compactness, worst concavity, worst symmetry, worst fractal dimension\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\r\n",
    "stdsc = StandardScaler()\r\n",
    "X_train_std = stdsc.fit_transform(X_train)\r\n",
    "print(X_train_std.shape)\r\n",
    "\r\n",
    "# Create classifier\r\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\r\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\r\n",
    "\r\n",
    "# Create selector object\r\n",
    "sel['seq_backward'] = SequentialFeatureSelector(knn, direction='backward', n_features_to_select=max_features, scoring='accuracy', cv=3, n_jobs=-1)\r\n",
    "\r\n",
    "# Training\r\n",
    "sel['seq_backward'].fit(X_train_std, y_train)\r\n",
    "\r\n",
    "# Get column boolean\r\n",
    "sup = sel['seq_backward'].get_support()\r\n",
    "print('\\nSupport array')\r\n",
    "print('-'*30)\r\n",
    "print(*sup, sep=', ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(398, 30)\n",
      "\n",
      "Support array\n",
      "------------------------------\n",
      "False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, False, False, False, False, True, False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Print columns\r\n",
    "cols = dfX.columns\r\n",
    "cols_sel = cols[sup]\r\n",
    "print('\\nChosen columns')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_sel, sep=', ')\r\n",
    "\r\n",
    "cols_rem = cols[np.logical_not(sup)]\r\n",
    "print(f'\\nRemoved columns')\r\n",
    "print('-'*30)\r\n",
    "print(*cols_rem, sep=', ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Chosen columns\n",
      "------------------------------\n",
      "mean concavity, worst texture, worst perimeter, worst area, worst symmetry\n",
      "\n",
      "Removed columns\n",
      "------------------------------\n",
      "mean radius, mean texture, mean perimeter, mean area, mean smoothness, mean compactness, mean concave points, mean symmetry, mean fractal dimension, radius error, texture error, perimeter error, area error, smoothness error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst radius, worst smoothness, worst compactness, worst concavity, worst concave points, worst fractal dimension\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training with random forrest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "paramSetAll = {\r\n",
    "    \"ex1\": {\r\n",
    "        \"criterion\": \"gini\",\r\n",
    "        \"n_estimators\": 25,\r\n",
    "        \"max_samples\": None,\r\n",
    "        \"max_features\": \"auto\",\r\n",
    "        \"max_depth\": None,\r\n",
    "    },\r\n",
    "    \"ex2\": {\r\n",
    "        \"criterion\": \"gini\",\r\n",
    "        \"n_estimators\": 50,\r\n",
    "        \"max_samples\": None,\r\n",
    "        \"max_features\": \"auto\",\r\n",
    "        \"max_depth\": None,\r\n",
    "    },\r\n",
    "    \"ex3\": {\r\n",
    "        \"criterion\": \"gini\",\r\n",
    "        \"n_estimators\": 100,\r\n",
    "        \"max_samples\": None,\r\n",
    "        \"max_features\": \"auto\",\r\n",
    "        \"max_depth\": None,\r\n",
    "    },\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "cl = list(range(1,4))\r\n",
    "ca = [ f'ex{i}' for i in cl]\r\n",
    "paramSet = { k: paramSetAll[k] for k in ca} \r\n",
    "print(paramSet)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'ex1': {'criterion': 'gini', 'n_estimators': 25, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}, 'ex2': {'criterion': 'gini', 'n_estimators': 50, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}, 'ex3': {'criterion': 'gini', 'n_estimators': 100, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def training(X_train, y_train, X_test, y_test):\r\n",
    "    for paramName, paramValue in paramSet.items():\r\n",
    "        # Extract parameteres\r\n",
    "        forrest = RandomForestClassifier(**paramValue)\r\n",
    "\r\n",
    "        # Training\r\n",
    "        forrest.fit(X_train, y_train)\r\n",
    "\r\n",
    "        # Prediction\r\n",
    "        y_pred = forrest.predict(X_test)\r\n",
    "\r\n",
    "        # Misclassification from the test samples\r\n",
    "        sumMiss = (y_test != y_pred).sum()\r\n",
    "\r\n",
    "        # Accuracy score from the test samples\r\n",
    "        accuracyScore = accuracy_score(y_test, y_pred)\r\n",
    "\r\n",
    "        print(f\"Parameters: {paramValue}\")\r\n",
    "        print(f\"Misclassified examples: {sumMiss}\")\r\n",
    "        print(f\"Accuracy score: {accuracyScore}\")\r\n",
    "        print(f\"--------------------------------------------------\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\r\n",
    "\r\n",
    "# Standardize\r\n",
    "stdsc = StandardScaler()\r\n",
    "X_train_std = stdsc.fit_transform(X_train)\r\n",
    "X_test_std = stdsc.transform(X_test)\r\n",
    "print(X_train_std.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(398, 30)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# No transformation\r\n",
    "training(X_train_std, y_train, X_test_std, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameters: {'criterion': 'gini', 'n_estimators': 25, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 13\n",
      "Accuracy score: 0.9239766081871345\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 50, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 9\n",
      "Accuracy score: 0.9473684210526315\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 100, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 9\n",
      "Accuracy score: 0.9473684210526315\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "X_train_std_trans = sel['L1'].transform(X_train_std)\r\n",
    "X_test_std_trans = sel['L1'].transform(X_test_std)\r\n",
    "\r\n",
    "training(X_train_std_trans, y_train, X_test_std_trans, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameters: {'criterion': 'gini', 'n_estimators': 25, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 11\n",
      "Accuracy score: 0.935672514619883\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 50, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 9\n",
      "Accuracy score: 0.9473684210526315\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 100, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 9\n",
      "Accuracy score: 0.9473684210526315\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "X_train_std_trans = sel['imp'].transform(X_train_std)\r\n",
    "X_test_std_trans = sel['imp'].transform(X_test_std)\r\n",
    "\r\n",
    "training(X_train_std_trans, y_train, X_test_std_trans, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameters: {'criterion': 'gini', 'n_estimators': 25, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 14\n",
      "Accuracy score: 0.9181286549707602\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 50, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 13\n",
      "Accuracy score: 0.9239766081871345\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 100, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 12\n",
      "Accuracy score: 0.9298245614035088\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "X_train_std_trans = sel['seq_forward'].transform(X_train_std)\r\n",
    "X_test_std_trans = sel['seq_forward'].transform(X_test_std)\r\n",
    "\r\n",
    "training(X_train_std_trans, y_train, X_test_std_trans, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameters: {'criterion': 'gini', 'n_estimators': 25, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 9\n",
      "Accuracy score: 0.9473684210526315\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 50, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 11\n",
      "Accuracy score: 0.935672514619883\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 100, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 9\n",
      "Accuracy score: 0.9473684210526315\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "X_train_std_trans = sel['seq_backward'].transform(X_train_std)\r\n",
    "X_test_std_trans = sel['seq_backward'].transform(X_test_std)\r\n",
    "\r\n",
    "training(X_train_std_trans, y_train, X_test_std_trans, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameters: {'criterion': 'gini', 'n_estimators': 25, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 14\n",
      "Accuracy score: 0.9181286549707602\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 50, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 9\n",
      "Accuracy score: 0.9473684210526315\n",
      "--------------------------------------------------\n",
      "Parameters: {'criterion': 'gini', 'n_estimators': 100, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}\n",
      "Misclassified examples: 8\n",
      "Accuracy score: 0.9532163742690059\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}